---
title: "Probability"
description: |
  Notes on Probability.
author:
  - name: Alex Stephenson
output:
  distill::distill_article:
    toc: true
    toc_depth: 3
    hightlight: haddock
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

The notes and notation come predominantly from Aronow and Miller (2019), Pittman (1993), and Casella and Berger (2002). 

## Fundamentals 

### Sample Spaces, Event Spaces, Probability Axioms 

A set *S* of subsets of a sample space $\Omega$ is an event space if it satisfies: 

  - Non-empty: $S \neq \emptyset$
  
  - Closed under complements: $A \in S \implies A^C \in S$
  
  - Closed under countable unions: $A_1,A_2,\cdot\cdot\cdot \in S \implies A_1 \cup A_2 \cup \cdot \cdot \cdot \in S$

A set *S* of subsets of some other set $\Omega$ that satisfies these properties is known as a $\sigma$-algebra on $\Omega$.

A **probability measure** is a function $P: S \rightarrow \mathbb{R}$ that assigns a probability to every event in the event space. 

### Kolmogorov's Axioms 

Let $\Omega, S, P$ be defined as above. Then $(\Omega, S, P)$ is a *probability space* if it satisfies: 

  - Non-negativity: $\forall A \in S, P(A) \geq 0$ and $P(A)$ is finite and real. 
  
  - Unitarity: $P(\Omega) = 1$
  
  - Countable additivity: If $A_1, A_2, ... \in S$ are pairwise disjoint $\forall i \neq j A_i \cap A_j = \emptyset$ implies $P(A_1 \cup A_2 \cup ...) = P(A_1) + P(A_2) + \cdot \cdot \cdot = \sum_iP(A_i)$
  
### Basic Properties of Probability 

Let $(\Omega, S, P)$ be a probability space. The following properties hold: 

  - Monotonicity: $\forall A,B \in S$ if $A \subseteq B \implies P(A) \leq P(B)$
  
  - Subtraction Rule: $\forall A,B \in S$ if $A \subseteq B \implies P(B\A) = P(B) - P(A)$
  
  - Zero Probability of the empty set: $P(\emptyset) = 0$
  
  - Probability Bounds: $\forall A \in S, 0 \leq P(A) \leq 1$
  
  - Complement Rule: $\forall A \in S, P(A^C) = 1 - P(A)$

### Joint and Continuous Probability 

The **joint probability** for $A,B \in S$ of A and B is $P(A \cap B)$

#### The Addition Rule 

For $A,B \in S, P(A \cup B) = P(A) + P(B) - P(A \cap B)$. In words the probability of at least one of two events occurring is equal to the sum of the probabilities of each occurring minus the probability of both occurring. 

#### Conditional Probability 

For $A,B \in S$ the **conditional probability** of A given B is $P(A|B) = \frac{P(A \cap B)}{P(B)}$ where $P(B) > 0$. 

The Multiplicative Law of Probability is a rearrangement $P(A|B)P(B) = P(A \cap B)$

#### Bayes Rule 

For $A,B \in S$ with $P(A) > 0$ and $P(B) > 0$

$$\begin{aligned}
P(A|B) = \frac{P(B|A)P(A)}{P(B)}
\end{aligned}$$

### The Law of Total Probability 

To understand the definition (and the utility) of the Law of Total Probability, first define a **partition** as the case if $A_1, A_2,... \in S$ are nonempty and pairwise disjoint and $\Omega = A_1 \cup A_2 \cup ...$ then $\{A_1, A_2, ...\}$ is a partition of $\Omega$. 

Partitions divide the sample space into mutually exclusive and exhaustive categories. Every outcome in the sample space is contained in exactly one event, so exactly one event in the partition occurs for any draw from the probability space. 

The **Law of Total Probability** states: 

If $\{A_1, A_2,... \}$ is a partition of $\Omega$ and $B \in S$ then $P(B) = \sum_i P(B \cap A_i)$. This can be equivalently stated as $P(B) = \sum_i P(B|A_i)P(A_i)$ in the event that $P(A_i) > 0, i = 1,2,3,...$.

The probability of an event B is thus a weighted average of the conditional probabilities of that event. The weights are the probabilities of the events that are being conditioned on. 

### Independence 

Presuming we have a random generative process, then events $A,B \in S$ are **independent** if $P(A \cap B) = P(A)P(B)$. This also means that for $A,B \in S$ with $P(B) > 0$ A and B are independent if and only if $P(A|B) = P(A)$. 

## Random Variables 

A **random variable** is a variable that takes on a real value that is determined by a random generative process. Formally, it is a function $X: \Omega \rightarrow \mathbb{R}$ such that $\forall r \in \mathbb{R}, \{\omega \in \Omega : X(\omega) \leq r \} \in S$.

We can think of random variables as mapping states of the world to a real number. There are two ways to apply a function to random variables. The first is to use the value of the random variable as an input to another function $g$. Formally, let $g: U \rightarrow mathbb{R}$ be a function where $X(\Omega) \subseteq U \subseteq \mathbb{R}$. If $g \circ X: \Omega \rightarrow \mathbb{R}$ is a random variable then we say that $g$ is a function of $X$. The second is to operate on the function itself.^[All random variables are implicitly defined within some probability space.]

### Discrete Random Variables 

A random variable X is **discrete** if its range $X(\Omega)$ is a countable set. 

Most variables tend to be discrete, though it can be mathematically simpler to represent some measurements that are discrete as continuous because we can use results from calculus. 

#### Probability Mass Function (pmf)

Given some discrete random variable X, we summarize the probability of each outcome x occurring with the **probability mass function**. The probability mass function of X is $f(x) = Pr[X=x], \forall x \in \mathbb{R}$

As an example of how a pmf works, suppose that we have a fair coin and we flip it repeatedly. Out of many coin flips, we expect heads and tails to come up half of the time. The pmf of the coin flip random variable is then:

$$\begin{aligned}
f(x) =\begin{cases}
 \frac{1}{2} & x \in \{H, T\} \\
 0 & otherwise
\end{cases}
\end{aligned}$$

A pmf tells us everything about a random variable's distribution. 

#### Discrete PMF properties 

For a discrete random variable X with pmf $f$

  - $\forall X \in \mathbb{R}, f(x) \geq 0$
  - \sum_{x \in X(\Omega)} f(x) = 1
  
More generally, for any set of events $D \subseteq \mathbb{R}$ and $A = \{X \in D\}$, $P(A) = Pr[X \in D] = \sum_{x \in X(A)}f(x)$. 

#### Cumulative Distribution Function (cdf) 

For a random variable X, the **cumulative distribution function** of X is $F(x) = Pr[X \leq x], \forall x \in \mathbb{R}$

The cdf returns the probability that an outcome for a random variable will be less than or equal to some given value. The cdf of X tells us everything that there is to know about X. 

#### Properties of cdf 

For a random variable X with cdf $F$:

  - $F$ is nondecreasing: $\forall x_1, x_2 \in \mathbb{R} x_1 < x_2 \implies F(x_1) \leq F(X_2)$
  - $\lim_{x \rightarrow -\infty} F(x) = 0$
  - $\lim_{x \rightarrow \infty} F(x) = 1$
  - $\forall x \in \mathbb{R}, 1- F(x) = Pr[X > x]$


### Continuous Random Variables 

If we are interested in some measurement that can take on an arbitrary degree of precision (e.g. time), we often represent this variable for mathematical convenience as a **continuous** random variable. Formally. a random variable X is continuous if there exists a non-negative function $f: \mathbb{R} \rightarrow \mathbb{R}$ such that the cdf of X is $F(x) = Pr[X \leq x] = \int_{-\infty}^x f(u)du, \forall x \in \mathbb{R}$

#### Probability Density Function (pdf)

The function $f$ is the **probability density function**. Due to the Fundamental Theorem of Calculus, the pdf is unique for any continuous random variable.

For a continuous random variable X with cdf $F$, the **probability density function** of X is $f(x) = \frac{dF(u)}{du}\big{|}_{u=x}, \forall x \in \mathbb{R}$. 

The pdf is the continuous analog to the pmf and consequently the properties of the pdf are analogous to the pmf. 

  - $\forall x \in \mathbb{R}, f(x) \geq 0$
  - $\int_{-\infty}^\infty f(x)dx = 1$

Because a continuous random variable is evaluated with an integral, $\forall x \in \mathbb{R}, Pr[X = x] = 0$. Furthermore: 

  - $\forall x \in \mathbb{R}, Pr[X < x] = Pr[X \leq x] = F(x) = \int_{-\infty}^x f(u)du$
  - $\forall x \in \mathbb{R}, Pr[X > x] = Pr[X \geq x] = 1 - F(x) = \int_{x}^\infty f(u)du$
  - $\forall a,b \in \mathbb{R}, a \leq b, Pr[a < X < b] = Pr[a \leq X < b] = Pr[a < X \leq B] = Pr[a \leq X \leq B] = F(b) - F(a) = \int_{a}^bf(x)dx$

## Bivariate Relationships 

## Multivariate Relationships 

